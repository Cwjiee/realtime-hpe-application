{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "94b274ab",
   "metadata": {},
   "source": [
    "# Yoga Pose Scoring"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f863040",
   "metadata": {},
   "source": [
    "## Imports and Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "16cb727f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from collections import deque\n",
    "import json\n",
    "import mediapipe as mp\n",
    "from mediapipe.tasks.python import vision\n",
    "from mediapipe.tasks import python\n",
    "import os\n",
    "import cv2\n",
    "import pandas as pd\n",
    "from cv2 import IMREAD_UNCHANGED\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96e546b6",
   "metadata": {},
   "source": [
    "## Map Landmark Mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "4294886d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def compute_angle(a, b, c):\n",
    "#     \"\"\"\n",
    "#     Compute angle ABC (in degrees) given 3 points.\n",
    "#     a, b, c are numpy arrays of shape (2,) or (3,)\n",
    "#     \"\"\"\n",
    "#     ba = a - b\n",
    "#     bc = c - b\n",
    "\n",
    "#     cosine_angle = np.dot(ba, bc) / (\n",
    "#         np.linalg.norm(ba) * np.linalg.norm(bc) + 1e-6\n",
    "#     )\n",
    "#     angle = np.arccos(np.clip(cosine_angle, -1.0, 1.0))\n",
    "#     return np.degrees(angle)\n",
    "\n",
    "def calculate_angle(a,b,c):\n",
    "    a = np.array(a) # First\n",
    "    b = np.array(b) # Mid\n",
    "    c = np.array(c) # End\n",
    "\n",
    "    radians = np.arctan2(c[1]-b[1], c[0]-b[0]) - np.arctan2(a[1]-b[1], a[0]-b[0])\n",
    "    angle = np.abs(radians*180.0/np.pi)\n",
    "\n",
    "    if angle > 180.0:\n",
    "        angle = 360-angle\n",
    "\n",
    "    return angle\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb8cb868",
   "metadata": {},
   "source": [
    "## Extract Pose Landmarks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "b22fcc0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1769751231.923845 4413215 gl_context.cc:407] GL version: 2.1 (2.1 Metal - 90.5), renderer: Apple M2\n",
      "W0000 00:00:1769751232.056426 4413217 inference_feedback_manager.cc:121] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1769751232.075870 4413216 inference_feedback_manager.cc:121] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n"
     ]
    }
   ],
   "source": [
    "# Create a PoseLandmarker object.\n",
    "base_options = mp.tasks.BaseOptions(\n",
    "    model_asset_path='pose_landmarker.task'\n",
    ")\n",
    "options = mp.tasks.vision.PoseLandmarkerOptions(\n",
    "    base_options=base_options,\n",
    "    running_mode=vision.RunningMode.IMAGE,\n",
    "    output_segmentation_masks=True)\n",
    "pose_landmarker = mp.tasks.vision.PoseLandmarker.create_from_options(options)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5602b48c",
   "metadata": {},
   "source": [
    "## Pose Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "f82247c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_landmarks(landmarks):\n",
    "    left_hip = landmarks[LANDMARKS[\"left_hip\"]]\n",
    "    right_hip = landmarks[LANDMARKS[\"right_hip\"]]\n",
    "    hip_center = (left_hip + right_hip) / 2\n",
    "\n",
    "    left_shoulder = landmarks[LANDMARKS[\"left_shoulder\"]]\n",
    "    right_shoulder = landmarks[LANDMARKS[\"right_shoulder\"]]\n",
    "    shoulder_width = np.linalg.norm(left_shoulder - right_shoulder) + 1e-6\n",
    "\n",
    "    normalized = (landmarks - hip_center) / shoulder_width\n",
    "    return normalized\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ddc49f0",
   "metadata": {},
   "source": [
    "## Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "8999878d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_joint_angles(lm):\n",
    "    return {\n",
    "        \"left_knee\": calculate_angle(\n",
    "            lm[LANDMARKS[\"left_hip\"]],\n",
    "            lm[LANDMARKS[\"left_knee\"]],\n",
    "            lm[LANDMARKS[\"left_ankle\"]],\n",
    "        ),\n",
    "        \"right_knee\": calculate_angle(\n",
    "            lm[LANDMARKS[\"right_hip\"]],\n",
    "            lm[LANDMARKS[\"right_knee\"]],\n",
    "            lm[LANDMARKS[\"right_ankle\"]],\n",
    "        ),\n",
    "        \"left_hip\": calculate_angle(\n",
    "            lm[LANDMARKS[\"left_shoulder\"]],\n",
    "            lm[LANDMARKS[\"left_hip\"]],\n",
    "            lm[LANDMARKS[\"left_knee\"]],\n",
    "        ),\n",
    "        \"right_hip\": calculate_angle(\n",
    "            lm[LANDMARKS[\"right_shoulder\"]],\n",
    "            lm[LANDMARKS[\"right_hip\"]],\n",
    "            lm[LANDMARKS[\"right_knee\"]],\n",
    "        ),\n",
    "        \"left_elbow\": calculate_angle(\n",
    "            lm[LANDMARKS[\"left_shoulder\"]],\n",
    "            lm[LANDMARKS[\"left_elbow\"]],\n",
    "            lm[LANDMARKS[\"left_wrist\"]],\n",
    "        ),\n",
    "        \"right_elbow\": calculate_angle(\n",
    "            lm[LANDMARKS[\"right_shoulder\"]],\n",
    "            lm[LANDMARKS[\"right_elbow\"]],\n",
    "            lm[LANDMARKS[\"right_wrist\"]],\n",
    "        ),\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8055745",
   "metadata": {},
   "source": [
    "## Reference Pose Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "43b1bf3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "LANDMARKS = {\n",
    "    \"left_shoulder\": 11,\n",
    "    \"right_shoulder\": 12,\n",
    "    \"left_elbow\": 13,\n",
    "    \"right_elbow\": 14,\n",
    "    \"left_wrist\": 15,\n",
    "    \"right_wrist\": 16,\n",
    "    \"left_hip\": 23,\n",
    "    \"right_hip\": 24,\n",
    "    \"left_knee\": 25,\n",
    "    \"right_knee\": 26,\n",
    "    \"left_ankle\": 27,\n",
    "    \"right_ankle\": 28\n",
    "}\n",
    "\n",
    "ANGLE_TOLERANCE = 15.0\n",
    "\n",
    "# lm = json.load(open('yoga_landmarks/tree_2.json'))\n",
    "lm = pd.read_json('yoga_landmarks/tree_2.json')\n",
    "lm = np.array(lm)\n",
    "reference_angles = extract_joint_angles(lm) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2933cf77",
   "metadata": {},
   "source": [
    "## MAE Based Pose Scoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "b97cb939",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def compute_weighted_mae(user_angles, ref_angles, weights):\n",
    "#     total_error = 0.0\n",
    "\n",
    "#     for joint, ref_angle in ref_angles.items():\n",
    "#         if joint not in user_angles:\n",
    "#             continue\n",
    "#         error = abs(user_angles[joint] - ref_angle)\n",
    "#         total_error += weights[joint] * error\n",
    "\n",
    "#     return total_error\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af5df77e",
   "metadata": {},
   "source": [
    "## Convert MAE to Score (0 - 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "d1220725",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_shortest_angle_distance(a, b):\n",
    "    \"\"\"Calculates the shortest distance between two angles in degrees.\"\"\"\n",
    "    diff = (b - a + 180) % 360 - 180\n",
    "    return abs(diff)\n",
    "\n",
    "def mae_to_score(mae, tolerance=ANGLE_TOLERANCE):\n",
    "    # sigma = tolerance\n",
    "    # score = np.exp(-0.5 * (mae / sigma) ** 2)\n",
    "    # return score * 100\n",
    "    \n",
    "    if mae <= tolerance:\n",
    "        return 100.0\n",
    "    cutoff = 45.0\n",
    "    score = max(0.0, 1.0 - (mae - tolerance) / (cutoff - tolerance))\n",
    "    # score = max(0.0, 1.0 - mae / tolerance)\n",
    "    return score * 100\n",
    "\n",
    "def compute_mae(user_angles, reference_pose):\n",
    "    total_error = 0.0\n",
    "    total_weight = 0.0\n",
    "\n",
    "    for joint, ref_angle in reference_pose.items():\n",
    "        if joint not in user_angles:\n",
    "            continue\n",
    "        error = get_shortest_angle_distance(user_angles[joint], ref_angle)\n",
    "        total_error += error\n",
    "        # total_error += abs(user_angles[joint] - ref_angle)\n",
    "        total_weight += 1\n",
    "\n",
    "    return total_error / (total_weight + 1e-6)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6f71a80",
   "metadata": {},
   "source": [
    "## Pose Scoring Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "7f7ae4ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_image(image_path):\n",
    "    image = cv2.imread(image_path, IMREAD_UNCHANGED)\n",
    "    if image is None:\n",
    "        raise ValueError(\"Image not found\")\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "c553104e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def score_pose_from_image(image):\n",
    "    rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    # Convert to MediaPipe Image\n",
    "    mp_image = mp.Image(\n",
    "        image_format=mp.ImageFormat.SRGB,\n",
    "        data=rgb\n",
    "    )\n",
    "\n",
    "    # Run pose landmarker\n",
    "    result = pose_landmarker.detect(mp_image)\n",
    "\n",
    "    if not result.pose_landmarks:\n",
    "        return None\n",
    "\n",
    "    # Extract landmarks (first detected person)\n",
    "    landmarks = result.pose_landmarks[0]\n",
    "\n",
    "    # Convert to numpy array (x, y only)\n",
    "    landmarks_np = np.array(\n",
    "        [[lm.x, lm.y] for lm in landmarks]\n",
    "    )\n",
    "\n",
    "    # Normalize + extract features\n",
    "    landmarks_np = normalize_landmarks(landmarks_np)\n",
    "    angles = extract_joint_angles(landmarks_np)\n",
    "\n",
    "    # Score\n",
    "    # reference_pose = get_tree_pose_reference(angles)\n",
    "    # mae = weighted_mae(angles, reference_pose, POSE_WEIGHTS)\n",
    "    mae = compute_mae(angles, reference_angles)\n",
    "    score = mae_to_score(mae)\n",
    "\n",
    "\n",
    "    return {\n",
    "        \"score\": round(score, 2),\n",
    "        \"mae\": round(mae, 2),\n",
    "        \"angles\": angles,\n",
    "        \"reference angles\": reference_angles,\n",
    "        \"landmarks\": landmarks,\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "21c11d2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# image = load_image(\"/Users/weijie/Downloads/archive/Vrksasana/File12.png\")\n",
    "# image = load_image(\"images/tree_2.jpg\")\n",
    "# image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "2179bb0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_result(image, show_plot):\n",
    "    result = score_pose_from_image(image)\n",
    "    landmark_list = result[\"landmarks\"]\n",
    "\n",
    "    if show_plot:\n",
    "        annotated_image = image.copy()\n",
    "        for idx, landmark in enumerate(landmark_list):\n",
    "            x, y = int(landmark.x * image.shape[1]), int(landmark.y * image.shape[0])\n",
    "            cv2.circle(annotated_image, (x, y), 5, (0, 255, 0), -1)\n",
    "\n",
    "            # Draw connections\n",
    "            connections = mp.tasks.vision.PoseLandmarksConnections.POSE_LANDMARKS\n",
    "            for connection in connections:\n",
    "                start_idx = connection.start\n",
    "                end_idx = connection.end\n",
    "                start_point = (int(landmark_list[start_idx].x * image.shape[1]),\n",
    "                                int(landmark_list[start_idx].y * image.shape[0]))\n",
    "                end_point = (int(landmark_list[end_idx].x * image.shape[1]),\n",
    "                                int(landmark_list[end_idx].y * image.shape[0]))\n",
    "                cv2.line(annotated_image, start_point, end_point, (255, 0, 0), 2)\n",
    "            \n",
    "        plt.figure(figsize=(10, 10))\n",
    "        plt.imshow(annotated_image)\n",
    "        plt.axis('off')\n",
    "        plt.show()\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "75294eed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score: 100.0\n",
      "mae: 10.83\n",
      "angles:\n",
      "\tleft_knee: 176.78557700680173\n",
      "\tright_knee: 14.79878241404864\n",
      "\tleft_hip: 178.25214707723663\n",
      "\tright_hip: 96.95392528194662\n",
      "\tleft_elbow: 21.94799571858269\n",
      "\tright_elbow: 21.551002255044317\n",
      "reference angles:\n",
      "\tleft_knee: 177.30304030599115\n",
      "\tright_knee: 38.94845179885842\n",
      "\tleft_hip: 175.15963930404658\n",
      "\tright_hip: 128.1149594409297\n",
      "\tleft_elbow: 25.71898900904405\n",
      "\tright_elbow: 23.825378119325517\n",
      "landmarks: [NormalizedLandmark(x=0.5982357263565063, y=0.09445592761039734, z=-0.7386676073074341, visibility=0.9998100399971008, presence=0.9999082088470459, name=None), NormalizedLandmark(x=0.6224892139434814, y=0.07729500532150269, z=-0.652359127998352, visibility=0.999818742275238, presence=0.9997265934944153, name=None), NormalizedLandmark(x=0.6370223164558411, y=0.07721284031867981, z=-0.6524774432182312, visibility=0.9997636675834656, presence=0.9996833801269531, name=None), NormalizedLandmark(x=0.6496479511260986, y=0.07757875323295593, z=-0.6525528430938721, visibility=0.9997615218162537, presence=0.9996260404586792, name=None), NormalizedLandmark(x=0.5731476545333862, y=0.07879742980003357, z=-0.635779619216919, visibility=0.9997974038124084, presence=0.9998142123222351, name=None), NormalizedLandmark(x=0.5567947030067444, y=0.07962778210639954, z=-0.6359774470329285, visibility=0.9997610449790955, presence=0.99981290102005, name=None), NormalizedLandmark(x=0.5403734445571899, y=0.08049720525741577, z=-0.6362767219543457, visibility=0.9998214840888977, presence=0.9998102784156799, name=None), NormalizedLandmark(x=0.6737003326416016, y=0.0884612500667572, z=-0.18086950480937958, visibility=0.999675989151001, presence=0.9997579455375671, name=None), NormalizedLandmark(x=0.5187637209892273, y=0.090971440076828, z=-0.10617577284574509, visibility=0.9998987913131714, presence=0.999904990196228, name=None), NormalizedLandmark(x=0.6270074844360352, y=0.11570575833320618, z=-0.5638405680656433, visibility=0.9998894929885864, presence=0.9998966455459595, name=None), NormalizedLandmark(x=0.5687056183815002, y=0.11578777432441711, z=-0.5427906513214111, visibility=0.999776303768158, presence=0.9999035596847534, name=None), NormalizedLandmark(x=0.7981977462768555, y=0.20924124121665955, z=-0.08333658427000046, visibility=0.999627947807312, presence=0.9992967844009399, name=None), NormalizedLandmark(x=0.40008723735809326, y=0.2108106017112732, z=0.09010661393404007, visibility=0.9983281493186951, presence=0.9984982013702393, name=None), NormalizedLandmark(x=0.9567441940307617, y=0.30727583169937134, z=-0.7290077805519104, visibility=0.9676547646522522, presence=0.9787241816520691, name=None), NormalizedLandmark(x=0.23535817861557007, y=0.3234577775001526, z=-0.5707108974456787, visibility=0.9860747456550598, presence=0.9666357636451721, name=None), NormalizedLandmark(x=0.6421300172805786, y=0.25303488969802856, z=-1.4188594818115234, visibility=0.9203091859817505, presence=0.9953943490982056, name=None), NormalizedLandmark(x=0.5368343591690063, y=0.2548832297325134, z=-1.3344680070877075, visibility=0.942707896232605, presence=0.9985727071762085, name=None), NormalizedLandmark(x=0.6002085208892822, y=0.22782324254512787, z=-1.5438051223754883, visibility=0.8186907172203064, presence=0.9950886368751526, name=None), NormalizedLandmark(x=0.5782619714736938, y=0.2257368564605713, z=-1.5057400465011597, visibility=0.8411993384361267, presence=0.9988251328468323, name=None), NormalizedLandmark(x=0.5984489917755127, y=0.2212025225162506, z=-1.4599336385726929, visibility=0.7928858399391174, presence=0.9966757297515869, name=None), NormalizedLandmark(x=0.5643224120140076, y=0.21788686513900757, z=-1.3817559480667114, visibility=0.8035407066345215, presence=0.9990645051002502, name=None), NormalizedLandmark(x=0.604693591594696, y=0.22934330999851227, z=-1.3922194242477417, visibility=0.7424957752227783, presence=0.9965934157371521, name=None), NormalizedLandmark(x=0.5596600770950317, y=0.22782684862613678, z=-1.3016700744628906, visibility=0.7532934546470642, presence=0.9990414977073669, name=None), NormalizedLandmark(x=0.7015055418014526, y=0.493929922580719, z=-0.13545893132686615, visibility=0.999691367149353, presence=0.9998525381088257, name=None), NormalizedLandmark(x=0.450557678937912, y=0.4780947268009186, z=0.13578829169273376, visibility=0.9977422952651978, presence=0.9994051456451416, name=None), NormalizedLandmark(x=0.6284088492393494, y=0.6893579959869385, z=-0.40832579135894775, visibility=0.8942734599113464, presence=0.9942371845245361, name=None), NormalizedLandmark(x=0.04602658748626709, y=0.6067849397659302, z=-0.4599779546260834, visibility=0.9299161434173584, presence=0.9731283783912659, name=None), NormalizedLandmark(x=0.5619683861732483, y=0.9027646780014038, z=0.1495799720287323, visibility=0.861290693283081, presence=0.895351767539978, name=None), NormalizedLandmark(x=0.44915056228637695, y=0.5867287516593933, z=0.9344455003738403, visibility=0.07818272709846497, presence=0.9937084913253784, name=None), NormalizedLandmark(x=0.5273470878601074, y=0.928608775138855, z=0.18664579093456268, visibility=0.5793834924697876, presence=0.8335193395614624, name=None), NormalizedLandmark(x=0.5322848558425903, y=0.5661173462867737, z=1.0832196474075317, visibility=0.1754951924085617, presence=0.9949243068695068, name=None), NormalizedLandmark(x=0.5500786304473877, y=0.9531874656677246, z=-0.28139176964759827, visibility=0.8258925676345825, presence=0.7681986689567566, name=None), NormalizedLandmark(x=0.5100402235984802, y=0.6392863392829895, z=1.0280578136444092, visibility=0.10315515846014023, presence=0.9893320798873901, name=None)]\n"
     ]
    }
   ],
   "source": [
    "image = load_image(\"/Users/weijie/Downloads/archive/Vrksasana/File24.png\")\n",
    "image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "result = show_result(image, show_plot=False)\n",
    "\n",
    "for k, v in result.items():\n",
    "    if k == 'angles' or k == 'reference angles':\n",
    "        print(f\"{k}:\")\n",
    "        for angle_k, angle_v in v.items():\n",
    "            print(f\"\\t{angle_k}: {angle_v}\")\n",
    "    else:\n",
    "        print(f\"{k}: {v}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa68b70f",
   "metadata": {},
   "source": [
    "## In Camera Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "d798c0ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class StabilityTracker:\n",
    "#     def __init__(self, window_size=30):\n",
    "#         self.window_size = window_size\n",
    "#         self.angle_history = deque(maxlen=window_size)\n",
    "\n",
    "#     def update(self, angles):\n",
    "#         self.angle_history.append(list(angles.values()))\n",
    "\n",
    "#     def stability_score(self):\n",
    "#         if len(self.angle_history) < 5:\n",
    "#             return 1.0  # not enough data to penalize\n",
    "\n",
    "#         variance = np.var(self.angle_history)\n",
    "#         stability = np.exp(-variance)\n",
    "#         return stability\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "e71452c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def score_pose(landmarks, stability_tracker=None):\n",
    "#     # Normalize\n",
    "#     landmarks = normalize_landmarks(landmarks)\n",
    "# \n",
    "#     # Extract angles\n",
    "#     user_angles = extract_joint_angles(landmarks)\n",
    "# \n",
    "#     # MAE scoring\n",
    "#     mae = compute_weighted_mae(\n",
    "#         user_angles,\n",
    "#         TREE_POSE_REFERENCE,\n",
    "#         TREE_POSE_WEIGHTS\n",
    "#     )\n",
    "# \n",
    "#     base_score = mae_to_score(mae)\n",
    "# \n",
    "#     # Stability bonus\n",
    "#     if stability_tracker:\n",
    "#         stability_tracker.update(user_angles)\n",
    "#         stability = stability_tracker.stability_score()\n",
    "#         final_score = base_score * stability\n",
    "#     else:\n",
    "#         final_score = base_score\n",
    "# \n",
    "#     return {\n",
    "#         \"score\": round(final_score, 2),\n",
    "#         \"mae\": round(mae, 2),\n",
    "#         \"angles\": user_angles\n",
    "#     }\n",
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "561a857b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# stability_tracker = StabilityTracker(window_size=45)\n",
    "# \n",
    "# # landmarks should be a (33, 2) or (33, 3) numpy array from MediaPipe\n",
    "# # Example:\n",
    "# # landmarks = np.array([[x0,y0], [x1,y1], ...])\n",
    "# \n",
    "# result = score_pose(landmarks, stability_tracker)\n",
    "# \n",
    "# print(\"Score:\", result[\"score\"])\n",
    "# print(\"MAE:\", result[\"mae\"])\n",
    "# "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
