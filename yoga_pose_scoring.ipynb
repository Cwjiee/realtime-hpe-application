{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "94b274ab",
   "metadata": {},
   "source": [
    "# Yoga Pose Scoring"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f863040",
   "metadata": {},
   "source": [
    "## Imports and Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "16cb727f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from collections import deque\n",
    "import json\n",
    "import mediapipe as mp\n",
    "from mediapipe.tasks.python import vision\n",
    "from mediapipe.tasks import python\n",
    "import os\n",
    "import cv2\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96e546b6",
   "metadata": {},
   "source": [
    "## Map Landmark Mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4294886d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def compute_angle(a, b, c):\n",
    "#     \"\"\"\n",
    "#     Compute angle ABC (in degrees) given 3 points.\n",
    "#     a, b, c are numpy arrays of shape (2,) or (3,)\n",
    "#     \"\"\"\n",
    "#     ba = a - b\n",
    "#     bc = c - b\n",
    "\n",
    "#     cosine_angle = np.dot(ba, bc) / (\n",
    "#         np.linalg.norm(ba) * np.linalg.norm(bc) + 1e-6\n",
    "#     )\n",
    "#     angle = np.arccos(np.clip(cosine_angle, -1.0, 1.0))\n",
    "#     return np.degrees(angle)\n",
    "\n",
    "def calculate_angle(a,b,c):\n",
    "    a = np.array(a) # First\n",
    "    b = np.array(b) # Mid\n",
    "    c = np.array(c) # End\n",
    "\n",
    "    radians = np.arctan2(c[1]-b[1], c[0]-b[0]) - np.arctan2(a[1]-b[1], a[0]-b[0])\n",
    "    angle = np.abs(radians*180.0/np.pi)\n",
    "\n",
    "    if angle > 180.0:\n",
    "        angle = 360-angle\n",
    "\n",
    "    return angle\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb8cb868",
   "metadata": {},
   "source": [
    "## Extract Pose Landmarks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "b22fcc0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1769138541.484364 3148015 gl_context.cc:407] GL version: 2.1 (2.1 Metal - 90.5), renderer: Apple M2\n",
      "W0000 00:00:1769138541.571710 3148016 inference_feedback_manager.cc:121] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1769138541.586389 3148018 inference_feedback_manager.cc:121] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n"
     ]
    }
   ],
   "source": [
    "# Create a PoseLandmarker object.\n",
    "base_options = mp.tasks.BaseOptions(\n",
    "    model_asset_path='pose_landmarker.task'\n",
    ")\n",
    "options = mp.tasks.vision.PoseLandmarkerOptions(\n",
    "    base_options=base_options,\n",
    "    running_mode=vision.RunningMode.IMAGE,\n",
    "    output_segmentation_masks=True)\n",
    "pose_landmarker = mp.tasks.vision.PoseLandmarker.create_from_options(options)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5602b48c",
   "metadata": {},
   "source": [
    "## Pose Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "f82247c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_landmarks(landmarks):\n",
    "    left_hip = landmarks[LANDMARKS[\"left_hip\"]]\n",
    "    right_hip = landmarks[LANDMARKS[\"right_hip\"]]\n",
    "    hip_center = (left_hip + right_hip) / 2\n",
    "\n",
    "    left_shoulder = landmarks[LANDMARKS[\"left_shoulder\"]]\n",
    "    right_shoulder = landmarks[LANDMARKS[\"right_shoulder\"]]\n",
    "    shoulder_width = np.linalg.norm(left_shoulder - right_shoulder) + 1e-6\n",
    "\n",
    "    normalized = (landmarks - hip_center) / shoulder_width\n",
    "    return normalized\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ddc49f0",
   "metadata": {},
   "source": [
    "## Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8999878d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_joint_angles(lm):\n",
    "    return {\n",
    "        \"left_knee\": calculate_angle(\n",
    "            lm[LANDMARKS[\"left_hip\"]],\n",
    "            lm[LANDMARKS[\"left_knee\"]],\n",
    "            lm[LANDMARKS[\"left_ankle\"]],\n",
    "        ),\n",
    "        \"right_knee\": calculate_angle(\n",
    "            lm[LANDMARKS[\"right_hip\"]],\n",
    "            lm[LANDMARKS[\"right_knee\"]],\n",
    "            lm[LANDMARKS[\"right_ankle\"]],\n",
    "        ),\n",
    "        \"left_hip\": calculate_angle(\n",
    "            lm[LANDMARKS[\"left_shoulder\"]],\n",
    "            lm[LANDMARKS[\"left_hip\"]],\n",
    "            lm[LANDMARKS[\"left_knee\"]],\n",
    "        ),\n",
    "        \"right_hip\": calculate_angle(\n",
    "            lm[LANDMARKS[\"right_shoulder\"]],\n",
    "            lm[LANDMARKS[\"right_hip\"]],\n",
    "            lm[LANDMARKS[\"right_knee\"]],\n",
    "        ),\n",
    "        \"left_elbow\": calculate_angle(\n",
    "            lm[LANDMARKS[\"left_shoulder\"]],\n",
    "            lm[LANDMARKS[\"left_elbow\"]],\n",
    "            lm[LANDMARKS[\"left_wrist\"]],\n",
    "        ),\n",
    "        \"right_elbow\": calculate_angle(\n",
    "            lm[LANDMARKS[\"right_shoulder\"]],\n",
    "            lm[LANDMARKS[\"right_elbow\"]],\n",
    "            lm[LANDMARKS[\"right_wrist\"]],\n",
    "        ),\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8055745",
   "metadata": {},
   "source": [
    "## Reference Pose Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "43b1bf3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "LANDMARKS = {\n",
    "    \"left_shoulder\": 11,\n",
    "    \"right_shoulder\": 12,\n",
    "    \"left_elbow\": 13,\n",
    "    \"right_elbow\": 14,\n",
    "    \"left_wrist\": 15,\n",
    "    \"right_wrist\": 16,\n",
    "    \"left_hip\": 23,\n",
    "    \"right_hip\": 24,\n",
    "    \"left_knee\": 25,\n",
    "    \"right_knee\": 26,\n",
    "    \"left_ankle\": 27,\n",
    "    \"right_ankle\": 28\n",
    "}\n",
    "\n",
    "ANGLE_TOLERANCE = 15.0\n",
    "\n",
    "# lm = json.load(open('yoga_landmarks/tree_2.json'))\n",
    "lm = pd.read_json('yoga_landmarks/tree_2.json')\n",
    "lm = np.array(lm)\n",
    "reference_angles = extract_joint_angles(lm) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2933cf77",
   "metadata": {},
   "source": [
    "## MAE Based Pose Scoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "b97cb939",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def compute_weighted_mae(user_angles, ref_angles, weights):\n",
    "#     total_error = 0.0\n",
    "\n",
    "#     for joint, ref_angle in ref_angles.items():\n",
    "#         if joint not in user_angles:\n",
    "#             continue\n",
    "#         error = abs(user_angles[joint] - ref_angle)\n",
    "#         total_error += weights[joint] * error\n",
    "\n",
    "#     return total_error\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af5df77e",
   "metadata": {},
   "source": [
    "## Convert MAE to Score (0 - 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1220725",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mae_to_score(mae, tolerance=ANGLE_TOLERANCE):\n",
    "    score = max(0.0, 1.0 - mae / tolerance)\n",
    "    return score * 100\n",
    "\n",
    "def compute_mae(user_angles, reference_pose):\n",
    "    total_error = 0.0\n",
    "    total_weight = 0.0\n",
    "\n",
    "    for joint, ref_angle in reference_pose.items():\n",
    "        if joint not in user_angles:\n",
    "            continue\n",
    "        total_error += abs(user_angles[joint] - ref_angle)\n",
    "        total_weight += 1\n",
    "\n",
    "    return total_error / (total_weight + 1e-6)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73e0a5c6",
   "metadata": {},
   "source": [
    "## Pose Holding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6f71a80",
   "metadata": {},
   "source": [
    "## Pose Scoring Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "c553104e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def score_pose_from_image(image_path):\n",
    "    # Load image\n",
    "    image = cv2.imread(image_path)\n",
    "    if image is None:\n",
    "        raise ValueError(\"Image not found\")\n",
    "\n",
    "    rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    # Convert to MediaPipe Image\n",
    "    mp_image = mp.Image(\n",
    "        image_format=mp.ImageFormat.SRGB,\n",
    "        data=rgb\n",
    "    )\n",
    "\n",
    "    # Run pose landmarker\n",
    "    result = pose_landmarker.detect(mp_image)\n",
    "\n",
    "    if not result.pose_landmarks:\n",
    "        return None\n",
    "\n",
    "    # Extract landmarks (first detected person)\n",
    "    landmarks = result.pose_landmarks[0]\n",
    "\n",
    "    # Convert to numpy array (x, y only)\n",
    "    landmarks_np = np.array(\n",
    "        [[lm.x, lm.y] for lm in landmarks]\n",
    "    )\n",
    "\n",
    "    # Normalize + extract features\n",
    "    landmarks_np = normalize_landmarks(landmarks_np)\n",
    "    angles = extract_joint_angles(landmarks_np)\n",
    "\n",
    "    # Score\n",
    "    # reference_pose = get_tree_pose_reference(angles)\n",
    "    # mae = weighted_mae(angles, reference_pose, POSE_WEIGHTS)\n",
    "    mae = compute_mae(angles, reference_angles)\n",
    "    score = mae_to_score(mae)\n",
    "\n",
    "\n",
    "    return {\n",
    "        \"score\": round(score, 2),\n",
    "        \"mae\": round(mae, 2),\n",
    "        \"angles\": angles\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "21c11d2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score: 99.04\n",
      "mae: 0.14\n",
      "angles:\n",
      "\tleft_knee: 177.12154210953838\n",
      "\tright_knee: 38.55234765075505\n",
      "\tleft_hip: 175.171054892176\n",
      "\tright_hip: 128.20825985150398\n",
      "\tleft_elbow: 25.706188291677265\n",
      "\tright_elbow: 23.997393141048395\n"
     ]
    }
   ],
   "source": [
    "result = score_pose_from_image(\"images/tree_2.jpg\")\n",
    "for k, v in result.items():\n",
    "    if k == 'angles':\n",
    "        print(f\"{k}:\")\n",
    "        for angle_k, angle_v in v.items():\n",
    "            print(f\"\\t{angle_k}: {angle_v}\")\n",
    "    else:\n",
    "        print(f\"{k}: {v}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa68b70f",
   "metadata": {},
   "source": [
    "## In Camera Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d798c0ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class StabilityTracker:\n",
    "#     def __init__(self, window_size=30):\n",
    "#         self.window_size = window_size\n",
    "#         self.angle_history = deque(maxlen=window_size)\n",
    "\n",
    "#     def update(self, angles):\n",
    "#         self.angle_history.append(list(angles.values()))\n",
    "\n",
    "#     def stability_score(self):\n",
    "#         if len(self.angle_history) < 5:\n",
    "#             return 1.0  # not enough data to penalize\n",
    "\n",
    "#         variance = np.var(self.angle_history)\n",
    "#         stability = np.exp(-variance)\n",
    "#         return stability\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "e71452c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def score_pose(landmarks, stability_tracker=None):\n",
    "#     # Normalize\n",
    "#     landmarks = normalize_landmarks(landmarks)\n",
    "# \n",
    "#     # Extract angles\n",
    "#     user_angles = extract_joint_angles(landmarks)\n",
    "# \n",
    "#     # MAE scoring\n",
    "#     mae = compute_weighted_mae(\n",
    "#         user_angles,\n",
    "#         TREE_POSE_REFERENCE,\n",
    "#         TREE_POSE_WEIGHTS\n",
    "#     )\n",
    "# \n",
    "#     base_score = mae_to_score(mae)\n",
    "# \n",
    "#     # Stability bonus\n",
    "#     if stability_tracker:\n",
    "#         stability_tracker.update(user_angles)\n",
    "#         stability = stability_tracker.stability_score()\n",
    "#         final_score = base_score * stability\n",
    "#     else:\n",
    "#         final_score = base_score\n",
    "# \n",
    "#     return {\n",
    "#         \"score\": round(final_score, 2),\n",
    "#         \"mae\": round(mae, 2),\n",
    "#         \"angles\": user_angles\n",
    "#     }\n",
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "561a857b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# stability_tracker = StabilityTracker(window_size=45)\n",
    "# \n",
    "# # landmarks should be a (33, 2) or (33, 3) numpy array from MediaPipe\n",
    "# # Example:\n",
    "# # landmarks = np.array([[x0,y0], [x1,y1], ...])\n",
    "# \n",
    "# result = score_pose(landmarks, stability_tracker)\n",
    "# \n",
    "# print(\"Score:\", result[\"score\"])\n",
    "# print(\"MAE:\", result[\"mae\"])\n",
    "# "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
