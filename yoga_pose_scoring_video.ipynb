{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "94b274ab",
   "metadata": {},
   "source": [
    "# Yoga Pose Scoring (Video)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f863040",
   "metadata": {},
   "source": [
    "## Imports and Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "16cb727f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from collections import deque\n",
    "import json\n",
    "import mediapipe as mp\n",
    "from mediapipe.tasks.python import vision\n",
    "from mediapipe.tasks import python\n",
    "import os\n",
    "import cv2\n",
    "import pandas as pd\n",
    "from cv2 import IMREAD_UNCHANGED\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96e546b6",
   "metadata": {},
   "source": [
    "## Map Landmark Mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4294886d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def compute_angle(a, b, c):\n",
    "#     \"\"\"\n",
    "#     Compute angle ABC (in degrees) given 3 points.\n",
    "#     a, b, c are numpy arrays of shape (2,) or (3,)\n",
    "#     \"\"\"\n",
    "#     ba = a - b\n",
    "#     bc = c - b\n",
    "\n",
    "#     cosine_angle = np.dot(ba, bc) / (\n",
    "#         np.linalg.norm(ba) * np.linalg.norm(bc) + 1e-6\n",
    "#     )\n",
    "#     angle = np.arccos(np.clip(cosine_angle, -1.0, 1.0))\n",
    "#     return np.degrees(angle)\n",
    "\n",
    "def calculate_angle(a,b,c):\n",
    "    a = np.array(a) # First\n",
    "    b = np.array(b) # Mid\n",
    "    c = np.array(c) # End\n",
    "\n",
    "    radians = np.arctan2(c[1]-b[1], c[0]-b[0]) - np.arctan2(a[1]-b[1], a[0]-b[0])\n",
    "    angle = np.abs(radians*180.0/np.pi)\n",
    "\n",
    "    if angle > 180.0:\n",
    "        angle = 360-angle\n",
    "\n",
    "    return angle\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb8cb868",
   "metadata": {},
   "source": [
    "## Extract Pose Landmarks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b22fcc0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1770549554.388246 13253454 gl_context.cc:407] GL version: 2.1 (2.1 Metal - 90.5), renderer: Apple M2\n",
      "W0000 00:00:1770549554.480253 13253456 inference_feedback_manager.cc:121] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1770549554.495841 13253456 inference_feedback_manager.cc:121] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n"
     ]
    }
   ],
   "source": [
    "# Create a PoseLandmarker object.\n",
    "base_options = mp.tasks.BaseOptions(\n",
    "    model_asset_path='pose_landmarker_heavy.task'\n",
    ")\n",
    "options = mp.tasks.vision.PoseLandmarkerOptions(\n",
    "    base_options=base_options,\n",
    "    running_mode=vision.RunningMode.VIDEO,\n",
    "    output_segmentation_masks=True)\n",
    "video_landmarker = mp.tasks.vision.PoseLandmarker.create_from_options(options)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5602b48c",
   "metadata": {},
   "source": [
    "## Pose Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f82247c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_landmarks(landmarks):\n",
    "    left_hip = landmarks[LANDMARKS[\"left_hip\"]]\n",
    "    right_hip = landmarks[LANDMARKS[\"right_hip\"]]\n",
    "    hip_center = (left_hip + right_hip) / 2\n",
    "\n",
    "    left_shoulder = landmarks[LANDMARKS[\"left_shoulder\"]]\n",
    "    right_shoulder = landmarks[LANDMARKS[\"right_shoulder\"]]\n",
    "    shoulder_width = np.linalg.norm(left_shoulder - right_shoulder) + 1e-6\n",
    "\n",
    "    normalized = (landmarks - hip_center) / shoulder_width\n",
    "    return normalized\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ddc49f0",
   "metadata": {},
   "source": [
    "## Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8999878d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_joint_angles(lm):\n",
    "    return {\n",
    "        \"left_knee\": calculate_angle(\n",
    "            lm[LANDMARKS[\"left_hip\"]],\n",
    "            lm[LANDMARKS[\"left_knee\"]],\n",
    "            lm[LANDMARKS[\"left_ankle\"]],\n",
    "        ),\n",
    "        \"right_knee\": calculate_angle(\n",
    "            lm[LANDMARKS[\"right_hip\"]],\n",
    "            lm[LANDMARKS[\"right_knee\"]],\n",
    "            lm[LANDMARKS[\"right_ankle\"]],\n",
    "        ),\n",
    "        \"left_hip\": calculate_angle(\n",
    "            lm[LANDMARKS[\"left_shoulder\"]],\n",
    "            lm[LANDMARKS[\"left_hip\"]],\n",
    "            lm[LANDMARKS[\"left_knee\"]],\n",
    "        ),\n",
    "        \"right_hip\": calculate_angle(\n",
    "            lm[LANDMARKS[\"right_shoulder\"]],\n",
    "            lm[LANDMARKS[\"right_hip\"]],\n",
    "            lm[LANDMARKS[\"right_knee\"]],\n",
    "        ),\n",
    "        # \"left_elbow\": calculate_angle(\n",
    "        #     lm[LANDMARKS[\"left_shoulder\"]],\n",
    "        #     lm[LANDMARKS[\"left_elbow\"]],\n",
    "        #     lm[LANDMARKS[\"left_wrist\"]],\n",
    "        # ),\n",
    "        # \"right_elbow\": calculate_angle(\n",
    "        #     lm[LANDMARKS[\"right_shoulder\"]],\n",
    "        #     lm[LANDMARKS[\"right_elbow\"]],\n",
    "        #     lm[LANDMARKS[\"right_wrist\"]],\n",
    "        # ),\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8055745",
   "metadata": {},
   "source": [
    "## Reference Pose Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "43b1bf3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "LANDMARKS = {\n",
    "    \"left_shoulder\": 11,\n",
    "    \"right_shoulder\": 12,\n",
    "    \"left_elbow\": 13,\n",
    "    \"right_elbow\": 14,\n",
    "    \"left_wrist\": 15,\n",
    "    \"right_wrist\": 16,\n",
    "    \"left_hip\": 23,\n",
    "    \"right_hip\": 24,\n",
    "    \"left_knee\": 25,\n",
    "    \"right_knee\": 26,\n",
    "    \"left_ankle\": 27,\n",
    "    \"right_ankle\": 28\n",
    "}\n",
    "\n",
    "ANGLE_TOLERANCE = 15.0\n",
    "\n",
    "# lm = json.load(open('yoga_landmarks/tree_2.json'))\n",
    "# lm = pd.read_json('yoga_landmarks/tree_2.json')\n",
    "# lm = np.array(lm)\n",
    "# reference_angles = extract_joint_angles(lm) \n",
    "with open('reference/ground_truth_tree.json', 'r') as f:\n",
    "    pose_library = json.load(f)\n",
    "\n",
    "reference_angles = pose_library[\"Vrksasana\"]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2933cf77",
   "metadata": {},
   "source": [
    "## MAE Based Pose Scoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b97cb939",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def compute_weighted_mae(user_angles, ref_angles, weights):\n",
    "#     total_error = 0.0\n",
    "\n",
    "#     for joint, ref_angle in ref_angles.items():\n",
    "#         if joint not in user_angles:\n",
    "#             continue\n",
    "#         error = abs(user_angles[joint] - ref_angle)\n",
    "#         total_error += weights[joint] * error\n",
    "\n",
    "#     return total_error\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af5df77e",
   "metadata": {},
   "source": [
    "## Convert MAE to Score (0 - 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d1220725",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_shortest_angle_distance(a, b):\n",
    "    \"\"\"Calculates the shortest distance between two angles in degrees.\"\"\"\n",
    "    diff = (b - a + 180) % 360 - 180\n",
    "    return abs(diff)\n",
    "\n",
    "def mae_to_score(mae, tolerance=ANGLE_TOLERANCE):\n",
    "    # sigma = tolerance\n",
    "    # score = np.exp(-0.5 * (mae / sigma) ** 2)\n",
    "    # return score * 100\n",
    "    \n",
    "    if mae <= tolerance:\n",
    "        return 100.0\n",
    "    cutoff = 45.0\n",
    "    score = max(0.0, 1.0 - (mae - tolerance) / (cutoff - tolerance))\n",
    "    # score = max(0.0, 1.0 - mae / tolerance)\n",
    "    return score * 100\n",
    "\n",
    "def compute_mae(user_angles, reference_pose):\n",
    "    total_error = 0.0\n",
    "    total_weight = 0.0\n",
    "\n",
    "    for joint, ref_angle in reference_pose.items():\n",
    "        if joint not in user_angles:\n",
    "            continue\n",
    "        error = get_shortest_angle_distance(user_angles[joint], ref_angle)\n",
    "        total_error += error\n",
    "        # total_error += abs(user_angles[joint] - ref_angle)\n",
    "        total_weight += 1\n",
    "\n",
    "    return total_error / (total_weight + 1e-6)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6f71a80",
   "metadata": {},
   "source": [
    "## Pose Scoring Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "7f7ae4ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_image(image_path):\n",
    "    image = cv2.imread(image_path, IMREAD_UNCHANGED)\n",
    "    if image is None:\n",
    "        raise ValueError(\"Image not found\")\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c553104e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def score_pose_from_image(image):\n",
    "    rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    # Convert to MediaPipe Image\n",
    "    mp_image = mp.Image(\n",
    "        image_format=mp.ImageFormat.SRGB,\n",
    "        data=rgb\n",
    "    )\n",
    "\n",
    "    # Run pose landmarker\n",
    "    result = pose_landmarker.detect(mp_image)\n",
    "\n",
    "    if not result.pose_landmarks:\n",
    "        return None\n",
    "\n",
    "    # Extract landmarks (first detected person)\n",
    "    landmarks = result.pose_landmarks[0]\n",
    "\n",
    "    # Convert to numpy array (x, y only)\n",
    "    landmarks_np = np.array(\n",
    "        [[lm.x, lm.y] for lm in landmarks]\n",
    "    )\n",
    "\n",
    "    # Normalize + extract features\n",
    "    landmarks_np = normalize_landmarks(landmarks_np)\n",
    "    angles = extract_joint_angles(landmarks_np)\n",
    "\n",
    "    # Score\n",
    "    # reference_pose = get_tree_pose_reference(angles)\n",
    "    # mae = weighted_mae(angles, reference_pose, POSE_WEIGHTS)\n",
    "    mae = compute_mae(angles, reference_angles)\n",
    "    score = mae_to_score(mae)\n",
    "\n",
    "\n",
    "    return {\n",
    "        \"score\": round(score, 2),\n",
    "        \"mae\": round(mae, 2),\n",
    "        \"angles\": angles,\n",
    "        \"reference angles\": reference_angles,\n",
    "        \"landmarks\": landmarks,\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "21c11d2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# image = load_image(\"/Users/weijie/Downloads/archive/Vrksasana/File12.png\")\n",
    "# image = load_image(\"images/tree_2.jpg\")\n",
    "# image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "2179bb0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_result(image, show_plot):\n",
    "    result = score_pose_from_image(image)\n",
    "    landmark_list = result[\"landmarks\"]\n",
    "\n",
    "    if show_plot:\n",
    "        annotated_image = image.copy()\n",
    "        for idx, landmark in enumerate(landmark_list):\n",
    "            x, y = int(landmark.x * image.shape[1]), int(landmark.y * image.shape[0])\n",
    "            cv2.circle(annotated_image, (x, y), 5, (0, 255, 0), -1)\n",
    "\n",
    "            # Draw connections\n",
    "            connections = mp.tasks.vision.PoseLandmarksConnections.POSE_LANDMARKS\n",
    "            for connection in connections:\n",
    "                start_idx = connection.start\n",
    "                end_idx = connection.end\n",
    "                start_point = (int(landmark_list[start_idx].x * image.shape[1]),\n",
    "                                int(landmark_list[start_idx].y * image.shape[0]))\n",
    "                end_point = (int(landmark_list[end_idx].x * image.shape[1]),\n",
    "                                int(landmark_list[end_idx].y * image.shape[0]))\n",
    "                cv2.line(annotated_image, start_point, end_point, (255, 0, 0), 2)\n",
    "            \n",
    "        plt.figure(figsize=(10, 10))\n",
    "        plt.imshow(annotated_image)\n",
    "        plt.axis('off')\n",
    "        plt.show()\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "75294eed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# image = load_image(\"/Users/weijie/Downloads/archive/Vrksasana/File20.png\")\n",
    "# image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "# \n",
    "# result = show_result(image, show_plot=True) # show plot = False to disable plot\n",
    "# \n",
    "# for k, v in result.items():\n",
    "#     if k == 'angles' or k == 'reference angles':\n",
    "#         print(f\"{k}:\")\n",
    "#         for angle_k, angle_v in v.items():\n",
    "#             print(f\"\\t{angle_k}: {angle_v}\")\n",
    "#     else:\n",
    "#         print(f\"{k}: {v}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5268749",
   "metadata": {},
   "source": [
    "# Batch Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "3a3c9a24",
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_process_video(input_path):\n",
    "    cap = cv2.VideoCapture(input_path)\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "    \n",
    "    all_frame_landmarks = [] \n",
    "    \n",
    "    # --- PHASE 1: Extraction Loop ---\n",
    "    print(\"Starting Landmark Extraction...\")\n",
    "    frame_index = 0\n",
    "    \n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        mp_image = mp.Image(image_format=mp.ImageFormat.SRGB, data=cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))\n",
    "        \n",
    "        timestamp_ms = int((frame_index / fps) * 1000)\n",
    "        \n",
    "        detection_result = video_landmarker.detect_for_video(mp_image, timestamp_ms)\n",
    "        \n",
    "        if detection_result.pose_landmarks:\n",
    "            all_frame_landmarks.append(detection_result.pose_landmarks[0])\n",
    "        else:\n",
    "            all_frame_landmarks.append(None)\n",
    "            \n",
    "        frame_index += 1\n",
    "\n",
    "    cap.release()\n",
    "    print(f\"Extraction Complete. Collected landmarks for {len(all_frame_landmarks)} frames.\")\n",
    "\n",
    "    # --- PHASE 2: Batch Scoring Loop ---\n",
    "    print(\"Starting Batch Scoring...\")\n",
    "    scores_over_time = []\n",
    "    \n",
    "    for i, landmarks in enumerate(all_frame_landmarks):\n",
    "        if landmarks is None:\n",
    "            scores_over_time.append(0.0) # Penalty for no detection\n",
    "            continue\n",
    "            \n",
    "        landmarks_np = np.array([[lm.x, lm.y] for lm in landmarks])\n",
    "\n",
    "        norm_landmarks = normalize_landmarks(landmarks_np)\n",
    "        \n",
    "        angles = extract_joint_angles(norm_landmarks)\n",
    "\n",
    "        mae = compute_mae(angles, reference_angles)\n",
    "        score = mae_to_score(mae)\n",
    "\n",
    "        # print(f\"Frame {i}:\")\n",
    "        # print(f\"  User Angles: {angles}\")\n",
    "        # print(f\"  Ref Angles: {reference_angles}\")\n",
    "        # print(f\"  MAE: {mae}\")\n",
    "        # print(f\"  Score: {score}\")\n",
    "        \n",
    "        scores_over_time.append(score)\n",
    "\n",
    "    return all_frame_landmarks, scores_over_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "5eb16743",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_batch_results(input_path, output_path, all_landmarks, all_scores):\n",
    "    cap = cv2.VideoCapture(input_path)\n",
    "    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "    \n",
    "    # Initialize VideoWriter\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'mp4v') \n",
    "    out = cv2.VideoWriter(output_path, fourcc, fps, (width, height))\n",
    "\n",
    "    print(\"Generating Visualized Video...\")\n",
    "    frame_index = 0\n",
    "    \n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        \n",
    "        # Get data for this frame (if available)\n",
    "        if frame_index < len(all_landmarks):\n",
    "            landmarks = all_landmarks[frame_index]\n",
    "            score = all_scores[frame_index]\n",
    "            \n",
    "            # --- DRAWING LOGIC STARTS HERE ---\n",
    "            if landmarks:\n",
    "                # 1. Draw Landmarks and Connections\n",
    "                # (Reusing the logic from your show_result function)\n",
    "                for idx, landmark in enumerate(landmarks):\n",
    "                    x, y = int(landmark.x * width), int(landmark.y * height)\n",
    "                    cv2.circle(frame, (x, y), 5, (0, 255, 0), -1)\n",
    "\n",
    "                connections = mp.tasks.vision.PoseLandmarksConnections.POSE_LANDMARKS\n",
    "                for connection in connections:\n",
    "                    start_idx = connection.start\n",
    "                    end_idx = connection.end\n",
    "                    \n",
    "                    # Ensure indices are valid\n",
    "                    if start_idx < len(landmarks) and end_idx < len(landmarks):\n",
    "                        start_point = (int(landmarks[start_idx].x * width), int(landmarks[start_idx].y * height))\n",
    "                        end_point = (int(landmarks[end_idx].x * width), int(landmarks[end_idx].y * height))\n",
    "                        cv2.line(frame, start_point, end_point, (255, 0, 0), 2)\n",
    "\n",
    "                # 2. Draw Score Text\n",
    "                cv2.putText(frame, f\"Score: {int(score)}\", (50, 100), \n",
    "                            cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 3)\n",
    "            # --- DRAWING LOGIC ENDS HERE ---\n",
    "\n",
    "        out.write(frame)\n",
    "        frame_index += 1\n",
    "\n",
    "    cap.release()\n",
    "    out.release()\n",
    "    print(f\"Video saved to {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "08bbc57d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "def save_scores_to_csv(video_path, scores, csv_path):\n",
    "    # 1. Get FPS to calculate accurate timestamps\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "    cap.release()\n",
    "\n",
    "    if fps == 0:\n",
    "        print(\"Error: Could not read FPS from video. Using default 30 FPS.\")\n",
    "        fps = 30.0\n",
    "\n",
    "    print(f\"Writing scores to {csv_path}...\")\n",
    "\n",
    "    # 2. Write to CSV\n",
    "    with open(csv_path, mode='w', newline='') as f:\n",
    "        writer = csv.writer(f)\n",
    "        \n",
    "        # Header\n",
    "        writer.writerow(['Frame Number', 'Timestamp (ms)', 'Score'])\n",
    "        \n",
    "        # Rows\n",
    "        for frame_idx, score in enumerate(scores):\n",
    "            # Calculate timestamp: (frame / fps) * 1000 to get milliseconds\n",
    "            timestamp_ms = int((frame_idx / fps) * 1000)\n",
    "            \n",
    "            # Write row\n",
    "            writer.writerow([frame_idx, timestamp_ms, f\"{score:.2f}\"])\n",
    "\n",
    "    print(f\"Successfully saved {len(scores)} rows to {csv_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "1046f54a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Landmark Extraction...\n",
      "Extraction Complete. Collected landmarks for 162 frames.\n",
      "Starting Batch Scoring...\n",
      "Generating Visualized Video...\n",
      "Video saved to yoga_scored.mp4\n",
      "Writing scores to yoga_scores.csv...\n",
      "Successfully saved 162 rows to yoga_scores.csv\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# path = \"/Users/weijie/Documents/cs/fyp/yoga_videos/tree_pose_trimmed\"\n",
    "# video_path = path + \".mp4\"\n",
    "# frame_scores = batch_process_video(video_path)\n",
    "# \n",
    "path = \"/Users/weijie/Documents/cs/fyp/yoga_videos/\"\n",
    "input_video = path + \"tree_pose_trimmed.mp4\"\n",
    "output_video = \"yoga_scored.mp4\"\n",
    "csv_output_path = \"yoga_scores.csv\"\n",
    "\n",
    "landmarks, scores = batch_process_video(input_video)\n",
    "\n",
    "visualize_batch_results(input_video, output_video, landmarks, scores)\n",
    "\n",
    "save_scores_to_csv(input_video, scores, csv_output_path)\n",
    "\n",
    "# Plot the score progression\n",
    "plt.plot(scores)\n",
    "plt.title(\"Yoga Pose Score Over Time\")\n",
    "plt.xlabel(\"Frame\")\n",
    "plt.ylabel(\"Score\")\n",
    "plt.show()\n",
    "\n",
    "# print(\"Displaying score of each frame\")\n",
    "# for score in scores:\n",
    "#     print(score)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa68b70f",
   "metadata": {},
   "source": [
    "## In Camera Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "d798c0ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class StabilityTracker:\n",
    "#     def __init__(self, window_size=30):\n",
    "#         self.window_size = window_size\n",
    "#         self.angle_history = deque(maxlen=window_size)\n",
    "\n",
    "#     def update(self, angles):\n",
    "#         self.angle_history.append(list(angles.values()))\n",
    "\n",
    "#     def stability_score(self):\n",
    "#         if len(self.angle_history) < 5:\n",
    "#             return 1.0  # not enough data to penalize\n",
    "\n",
    "#         variance = np.var(self.angle_history)\n",
    "#         stability = np.exp(-variance)\n",
    "#         return stability\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "e71452c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def score_pose(landmarks, stability_tracker=None):\n",
    "#     # Normalize\n",
    "#     landmarks = normalize_landmarks(landmarks)\n",
    "# \n",
    "#     # Extract angles\n",
    "#     user_angles = extract_joint_angles(landmarks)\n",
    "# \n",
    "#     # MAE scoring\n",
    "#     mae = compute_weighted_mae(\n",
    "#         user_angles,\n",
    "#         TREE_POSE_REFERENCE,\n",
    "#         TREE_POSE_WEIGHTS\n",
    "#     )\n",
    "# \n",
    "#     base_score = mae_to_score(mae)\n",
    "# \n",
    "#     # Stability bonus\n",
    "#     if stability_tracker:\n",
    "#         stability_tracker.update(user_angles)\n",
    "#         stability = stability_tracker.stability_score()\n",
    "#         final_score = base_score * stability\n",
    "#     else:\n",
    "#         final_score = base_score\n",
    "# \n",
    "#     return {\n",
    "#         \"score\": round(final_score, 2),\n",
    "#         \"mae\": round(mae, 2),\n",
    "#         \"angles\": user_angles\n",
    "#     }\n",
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "561a857b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# stability_tracker = StabilityTracker(window_size=45)\n",
    "# \n",
    "# # landmarks should be a (33, 2) or (33, 3) numpy array from MediaPipe\n",
    "# # Example:\n",
    "# # landmarks = np.array([[x0,y0], [x1,y1], ...])\n",
    "# \n",
    "# result = score_pose(landmarks, stability_tracker)\n",
    "# \n",
    "# print(\"Score:\", result[\"score\"])\n",
    "# print(\"MAE:\", result[\"mae\"])\n",
    "# "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
